{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad403974",
   "metadata": {},
   "source": [
    "# Import des librairies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "10e3ac8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import imblearn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff788350",
   "metadata": {},
   "source": [
    "# Import des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f8a2a68e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('donnée/data_rdy.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "892b61f4",
   "metadata": {},
   "source": [
    "# Préparation des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1f054687",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = df[df['TARGET'].notnull()]\n",
    "\n",
    "# Destiné à Kaggle\n",
    "test_df = df[df['TARGET'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8c9ccd07",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>SK_ID_CURR</th>\n",
       "      <th>TARGET</th>\n",
       "      <th>CODE_GENDER</th>\n",
       "      <th>FLAG_OWN_CAR</th>\n",
       "      <th>FLAG_OWN_REALTY</th>\n",
       "      <th>CNT_CHILDREN</th>\n",
       "      <th>AMT_INCOME_TOTAL</th>\n",
       "      <th>AMT_CREDIT</th>\n",
       "      <th>AMT_ANNUITY</th>\n",
       "      <th>...</th>\n",
       "      <th>CC_NAME_CONTRACT_STATUS_Signed_MAX</th>\n",
       "      <th>CC_NAME_CONTRACT_STATUS_Signed_MEAN</th>\n",
       "      <th>CC_NAME_CONTRACT_STATUS_Signed_SUM</th>\n",
       "      <th>CC_NAME_CONTRACT_STATUS_Signed_VAR</th>\n",
       "      <th>CC_NAME_CONTRACT_STATUS_nan_MIN</th>\n",
       "      <th>CC_NAME_CONTRACT_STATUS_nan_MAX</th>\n",
       "      <th>CC_NAME_CONTRACT_STATUS_nan_MEAN</th>\n",
       "      <th>CC_NAME_CONTRACT_STATUS_nan_SUM</th>\n",
       "      <th>CC_NAME_CONTRACT_STATUS_nan_VAR</th>\n",
       "      <th>CC_COUNT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>36</td>\n",
       "      <td>100043</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>198000.0</td>\n",
       "      <td>641173.5</td>\n",
       "      <td>23157.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>33.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>85</td>\n",
       "      <td>100100</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>202500.0</td>\n",
       "      <td>796396.5</td>\n",
       "      <td>38443.5</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.031915</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.031229</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>94.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>111</td>\n",
       "      <td>100131</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>270000.0</td>\n",
       "      <td>891072.0</td>\n",
       "      <td>45625.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>119</td>\n",
       "      <td>100139</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>157500.0</td>\n",
       "      <td>302341.5</td>\n",
       "      <td>24016.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>75.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>124</td>\n",
       "      <td>100145</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>202500.0</td>\n",
       "      <td>260725.5</td>\n",
       "      <td>16789.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>96.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307469</th>\n",
       "      <td>307473</td>\n",
       "      <td>456213</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>90000.0</td>\n",
       "      <td>258709.5</td>\n",
       "      <td>20439.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>34.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307471</th>\n",
       "      <td>307475</td>\n",
       "      <td>456215</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>144000.0</td>\n",
       "      <td>1303200.0</td>\n",
       "      <td>46809.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>94.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307475</th>\n",
       "      <td>307479</td>\n",
       "      <td>456219</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112500.0</td>\n",
       "      <td>521280.0</td>\n",
       "      <td>31630.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307496</th>\n",
       "      <td>307500</td>\n",
       "      <td>456244</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>261000.0</td>\n",
       "      <td>1303812.0</td>\n",
       "      <td>35982.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>41.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307499</th>\n",
       "      <td>307503</td>\n",
       "      <td>456247</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>112500.0</td>\n",
       "      <td>345510.0</td>\n",
       "      <td>17770.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>95.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9433 rows × 798 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         index  SK_ID_CURR  TARGET  CODE_GENDER  FLAG_OWN_CAR  \\\n",
       "36          36      100043     0.0            1             0   \n",
       "85          85      100100     0.0            0             1   \n",
       "111        111      100131     0.0            1             0   \n",
       "119        119      100139     0.0            1             0   \n",
       "124        124      100145     0.0            1             1   \n",
       "...        ...         ...     ...          ...           ...   \n",
       "307469  307473      456213     0.0            1             1   \n",
       "307471  307475      456215     1.0            1             0   \n",
       "307475  307479      456219     0.0            1             0   \n",
       "307496  307500      456244     0.0            1             0   \n",
       "307499  307503      456247     0.0            1             0   \n",
       "\n",
       "        FLAG_OWN_REALTY  CNT_CHILDREN  AMT_INCOME_TOTAL  AMT_CREDIT  \\\n",
       "36                    0             2          198000.0    641173.5   \n",
       "85                    0             2          202500.0    796396.5   \n",
       "111                   0             0          270000.0    891072.0   \n",
       "119                   1             1          157500.0    302341.5   \n",
       "124                   0             1          202500.0    260725.5   \n",
       "...                 ...           ...               ...         ...   \n",
       "307469                0             1           90000.0    258709.5   \n",
       "307471                1             1          144000.0   1303200.0   \n",
       "307475                0             1          112500.0    521280.0   \n",
       "307496                0             0          261000.0   1303812.0   \n",
       "307499                0             0          112500.0    345510.0   \n",
       "\n",
       "        AMT_ANNUITY  ...  CC_NAME_CONTRACT_STATUS_Signed_MAX  \\\n",
       "36          23157.0  ...                                 0.0   \n",
       "85          38443.5  ...                                 1.0   \n",
       "111         45625.5  ...                                 0.0   \n",
       "119         24016.5  ...                                 0.0   \n",
       "124         16789.5  ...                                 0.0   \n",
       "...             ...  ...                                 ...   \n",
       "307469      20439.0  ...                                 0.0   \n",
       "307471      46809.0  ...                                 0.0   \n",
       "307475      31630.5  ...                                 0.0   \n",
       "307496      35982.0  ...                                 0.0   \n",
       "307499      17770.5  ...                                 0.0   \n",
       "\n",
       "        CC_NAME_CONTRACT_STATUS_Signed_MEAN  \\\n",
       "36                                 0.000000   \n",
       "85                                 0.031915   \n",
       "111                                0.000000   \n",
       "119                                0.000000   \n",
       "124                                0.000000   \n",
       "...                                     ...   \n",
       "307469                             0.000000   \n",
       "307471                             0.000000   \n",
       "307475                             0.000000   \n",
       "307496                             0.000000   \n",
       "307499                             0.000000   \n",
       "\n",
       "        CC_NAME_CONTRACT_STATUS_Signed_SUM  \\\n",
       "36                                     0.0   \n",
       "85                                     3.0   \n",
       "111                                    0.0   \n",
       "119                                    0.0   \n",
       "124                                    0.0   \n",
       "...                                    ...   \n",
       "307469                                 0.0   \n",
       "307471                                 0.0   \n",
       "307475                                 0.0   \n",
       "307496                                 0.0   \n",
       "307499                                 0.0   \n",
       "\n",
       "        CC_NAME_CONTRACT_STATUS_Signed_VAR  CC_NAME_CONTRACT_STATUS_nan_MIN  \\\n",
       "36                                0.000000                              0.0   \n",
       "85                                0.031229                              0.0   \n",
       "111                               0.000000                              0.0   \n",
       "119                               0.000000                              0.0   \n",
       "124                               0.000000                              0.0   \n",
       "...                                    ...                              ...   \n",
       "307469                            0.000000                              0.0   \n",
       "307471                            0.000000                              0.0   \n",
       "307475                            0.000000                              0.0   \n",
       "307496                            0.000000                              0.0   \n",
       "307499                            0.000000                              0.0   \n",
       "\n",
       "        CC_NAME_CONTRACT_STATUS_nan_MAX  CC_NAME_CONTRACT_STATUS_nan_MEAN  \\\n",
       "36                                  0.0                               0.0   \n",
       "85                                  0.0                               0.0   \n",
       "111                                 0.0                               0.0   \n",
       "119                                 0.0                               0.0   \n",
       "124                                 0.0                               0.0   \n",
       "...                                 ...                               ...   \n",
       "307469                              0.0                               0.0   \n",
       "307471                              0.0                               0.0   \n",
       "307475                              0.0                               0.0   \n",
       "307496                              0.0                               0.0   \n",
       "307499                              0.0                               0.0   \n",
       "\n",
       "        CC_NAME_CONTRACT_STATUS_nan_SUM  CC_NAME_CONTRACT_STATUS_nan_VAR  \\\n",
       "36                                  0.0                              0.0   \n",
       "85                                  0.0                              0.0   \n",
       "111                                 0.0                              0.0   \n",
       "119                                 0.0                              0.0   \n",
       "124                                 0.0                              0.0   \n",
       "...                                 ...                              ...   \n",
       "307469                              0.0                              0.0   \n",
       "307471                              0.0                              0.0   \n",
       "307475                              0.0                              0.0   \n",
       "307496                              0.0                              0.0   \n",
       "307499                              0.0                              0.0   \n",
       "\n",
       "        CC_COUNT  \n",
       "36          33.0  \n",
       "85          94.0  \n",
       "111         24.0  \n",
       "119         75.0  \n",
       "124         96.0  \n",
       "...          ...  \n",
       "307469      34.0  \n",
       "307471      94.0  \n",
       "307475      10.0  \n",
       "307496      41.0  \n",
       "307499      95.0  \n",
       "\n",
       "[9433 rows x 798 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# On retire les informations qui ne sont pas des features\n",
    "\n",
    "feats = [f for f in train_df.columns if f not in ['TARGET','SK_ID_CURR','SK_ID_BUREAU','SK_ID_PREV','index']]\n",
    "\n",
    "correlation = train_df[feats].corrwith(train_df['TARGET'])\n",
    "\n",
    "feature = list(correlation.abs().sort_values(ascending=False)[:20].index)\n",
    "\n",
    "train_rdy = train_df.dropna(subset = feature)\n",
    "train_rdy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e1ae8fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On prend un sample des données pour gagner du temps\n",
    "\n",
    "#train_rdy_sample = train_rdy.sample(frac=0.3,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "002b4915",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On vérifie que l'imbalance est bien conservé\n",
    "\n",
    "#dict(train_rdy_sample['TARGET'].value_counts()/len(train_rdy_sample['TARGET'])*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fabb1507",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On récupère notre x et notre y\n",
    "\n",
    "X = train_rdy[feature]\n",
    "y = train_rdy[['TARGET']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9eff16f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# On prend un X_train et y_train\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a6f649be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On prend un sample des données pour gagner du temps\n",
    "\n",
    "X_train_sample, X_test_sample, y_train_sample, y_test_sample = train_test_split(X_train,y_train,train_size=0.4,random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c1d3baab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3018, 20)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_sample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8178a2cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0.0: 90.15904572564612, 1.0: 9.840954274353876}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# On vérifie que l'imbalance est bien conservé\n",
    "\n",
    "dict(y_train_sample['TARGET'].value_counts()/len(y_train_sample['TARGET'])*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d425607d",
   "metadata": {},
   "source": [
    "# Fine tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3a5e9407",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Score\n",
    "from sklearn.metrics import fbeta_score, make_scorer, roc_auc_score\n",
    "\n",
    "#Pipeline\n",
    "from imblearn.pipeline import Pipeline\n",
    "\n",
    "# Gridsearch\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Logistic regression\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# SMOTE pour le sampling\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# On prépare le fbetascore pour le gridsearch\n",
    "\n",
    "# Le fbeta_score permet de maximiser la pénalité sur les faux négatifs. Il servira à évaluer la performance final de nos modèles\n",
    "ftwo_scorer = make_scorer(fbeta_score, beta=10)\n",
    "\n",
    "# On prépare le roc_auc_score pour le gridsearch\n",
    "\n",
    "roc_auc = make_scorer(roc_auc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1214451d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c94bba38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Commençons par faire fonctionner notre modèle avec les paramètres d'origine\n",
    "\n",
    "model_logistic = Pipeline([\n",
    "        ('sampling', SMOTE()),\n",
    "        ('classification', LogisticRegression())\n",
    "        ])\n",
    "    \n",
    "param_orig = {'classification__tol': [0.0009326033468832199],\n",
    "                'classification__solver': ['liblinear'],\n",
    "                'classification__penalty': ['l1'],\n",
    "                'classification__max_iter': [1000],\n",
    "                'classification__C': [18589.56679635688]}\n",
    "    \n",
    "search_logi_ftwo_o = RandomizedSearchCV(estimator = model_logistic,scoring = ftwo_scorer,\\\n",
    "                               param_distributions =param_orig, n_iter = 20, cv = 5,\\\n",
    "                               verbose=2, random_state=0, n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4696987a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Louis\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\model_selection\\_search.py:306: UserWarning: The total space of parameters 1 is smaller than n_iter=20. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Louis\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\utils\\validation.py:1141: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=5,\n",
       "                   estimator=Pipeline(steps=[(&#x27;sampling&#x27;, SMOTE()),\n",
       "                                             (&#x27;classification&#x27;,\n",
       "                                              LogisticRegression())]),\n",
       "                   n_iter=20, n_jobs=-1,\n",
       "                   param_distributions={&#x27;classification__C&#x27;: [18589.56679635688],\n",
       "                                        &#x27;classification__max_iter&#x27;: [1000],\n",
       "                                        &#x27;classification__penalty&#x27;: [&#x27;l1&#x27;],\n",
       "                                        &#x27;classification__solver&#x27;: [&#x27;liblinear&#x27;],\n",
       "                                        &#x27;classification__tol&#x27;: [0.0009326033468832199]},\n",
       "                   random_state=0, scoring=make_scorer(fbeta_score, beta=10),\n",
       "                   verbose=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=5,\n",
       "                   estimator=Pipeline(steps=[(&#x27;sampling&#x27;, SMOTE()),\n",
       "                                             (&#x27;classification&#x27;,\n",
       "                                              LogisticRegression())]),\n",
       "                   n_iter=20, n_jobs=-1,\n",
       "                   param_distributions={&#x27;classification__C&#x27;: [18589.56679635688],\n",
       "                                        &#x27;classification__max_iter&#x27;: [1000],\n",
       "                                        &#x27;classification__penalty&#x27;: [&#x27;l1&#x27;],\n",
       "                                        &#x27;classification__solver&#x27;: [&#x27;liblinear&#x27;],\n",
       "                                        &#x27;classification__tol&#x27;: [0.0009326033468832199]},\n",
       "                   random_state=0, scoring=make_scorer(fbeta_score, beta=10),\n",
       "                   verbose=2)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;sampling&#x27;, SMOTE()),\n",
       "                (&#x27;classification&#x27;, LogisticRegression())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SMOTE</label><div class=\"sk-toggleable__content\"><pre>SMOTE()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=5,\n",
       "                   estimator=Pipeline(steps=[('sampling', SMOTE()),\n",
       "                                             ('classification',\n",
       "                                              LogisticRegression())]),\n",
       "                   n_iter=20, n_jobs=-1,\n",
       "                   param_distributions={'classification__C': [18589.56679635688],\n",
       "                                        'classification__max_iter': [1000],\n",
       "                                        'classification__penalty': ['l1'],\n",
       "                                        'classification__solver': ['liblinear'],\n",
       "                                        'classification__tol': [0.0009326033468832199]},\n",
       "                   random_state=0, scoring=make_scorer(fbeta_score, beta=10),\n",
       "                   verbose=2)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_logi_ftwo_o.fit(X_train_sample,y_train_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "65759807",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>score</th>\n",
       "      <th>best_params</th>\n",
       "      <th>best_score</th>\n",
       "      <th>train</th>\n",
       "      <th>test</th>\n",
       "      <th>fbeta_score_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>search_gradiant</td>\n",
       "      <td>ftwo</td>\n",
       "      <td>{'classification__tol': 0.0009326033468832199,...</td>\n",
       "      <td>0.61348</td>\n",
       "      <td>0.644248</td>\n",
       "      <td>0.624637</td>\n",
       "      <td>0.624637</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             model score                                        best_params  \\\n",
       "0  search_gradiant  ftwo  {'classification__tol': 0.0009326033468832199,...   \n",
       "\n",
       "   best_score     train      test  fbeta_score_test  \n",
       "0     0.61348  0.644248  0.624637          0.624637  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_model = search_logi_ftwo_o\n",
    "\n",
    "y_predict = current_model.predict(X_test)\n",
    "\n",
    "report_final = pd.DataFrame({'model':'search_gradiant','score':['ftwo'],'best_params':[current_model.best_params_],\\\n",
    "          'best_score':[current_model.best_score_],'train':[current_model.score(X_train, y_train)],\\\n",
    "          'test':[current_model.score(X_test, y_test)],'fbeta_score_test':[fbeta_score(y_test,y_predict,beta=10)]})\n",
    "\n",
    "report_final\n",
    "\n",
    "# Par erreur, on a appellé le modèle search_gradiant au lieu de search_logi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6b62dc12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Essayons de nouveau paramètre\n",
    "\n",
    "model_logistic = Pipeline([\n",
    "        ('sampling', SMOTE()),\n",
    "        ('classification', LogisticRegression())\n",
    "    ])\n",
    "\n",
    "random_grid = {'classification__tol': np.logspace(-4, -2, 100),\n",
    "                'classification__solver': ['liblinear'],\n",
    "                'classification__penalty': ['l1'],\n",
    "                'classification__max_iter': [900,1000,1100,1200,1300,1400,1500],\n",
    "                'classification__C': np.logspace(-5, 5,1000)\n",
    "              }\n",
    "\n",
    "search_logi_ftwo = RandomizedSearchCV(estimator = model_logistic,scoring = ftwo_scorer,\\\n",
    "                               param_distributions =random_grid, n_iter = 100, cv = 5,\\\n",
    "                               verbose=2, random_state=0, n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e4c93c76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Louis\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\utils\\validation.py:1141: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=5,\n",
       "                   estimator=Pipeline(steps=[(&#x27;sampling&#x27;, SMOTE()),\n",
       "                                             (&#x27;classification&#x27;,\n",
       "                                              LogisticRegression())]),\n",
       "                   n_iter=100, n_jobs=-1,\n",
       "                   param_distributions={&#x27;classification__C&#x27;: array([1.00000000e-05, 1.02331658e-05, 1.04717682e-05, 1.07159340e-05,\n",
       "       1.09657929e-05, 1.12214777e-05, 1.14831241e-05, 1.17508713e-05,\n",
       "       1.20248614e-05, 1.23052400e-05, 1.25921561e-05, 1.2...\n",
       "       0.00259502, 0.00271859, 0.00284804, 0.00298365, 0.00312572,\n",
       "       0.00327455, 0.00343047, 0.00359381, 0.00376494, 0.00394421,\n",
       "       0.00413201, 0.00432876, 0.00453488, 0.00475081, 0.00497702,\n",
       "       0.00521401, 0.00546228, 0.00572237, 0.00599484, 0.00628029,\n",
       "       0.00657933, 0.00689261, 0.00722081, 0.00756463, 0.00792483,\n",
       "       0.00830218, 0.00869749, 0.00911163, 0.00954548, 0.01      ])},\n",
       "                   random_state=0, scoring=make_scorer(fbeta_score, beta=10),\n",
       "                   verbose=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=5,\n",
       "                   estimator=Pipeline(steps=[(&#x27;sampling&#x27;, SMOTE()),\n",
       "                                             (&#x27;classification&#x27;,\n",
       "                                              LogisticRegression())]),\n",
       "                   n_iter=100, n_jobs=-1,\n",
       "                   param_distributions={&#x27;classification__C&#x27;: array([1.00000000e-05, 1.02331658e-05, 1.04717682e-05, 1.07159340e-05,\n",
       "       1.09657929e-05, 1.12214777e-05, 1.14831241e-05, 1.17508713e-05,\n",
       "       1.20248614e-05, 1.23052400e-05, 1.25921561e-05, 1.2...\n",
       "       0.00259502, 0.00271859, 0.00284804, 0.00298365, 0.00312572,\n",
       "       0.00327455, 0.00343047, 0.00359381, 0.00376494, 0.00394421,\n",
       "       0.00413201, 0.00432876, 0.00453488, 0.00475081, 0.00497702,\n",
       "       0.00521401, 0.00546228, 0.00572237, 0.00599484, 0.00628029,\n",
       "       0.00657933, 0.00689261, 0.00722081, 0.00756463, 0.00792483,\n",
       "       0.00830218, 0.00869749, 0.00911163, 0.00954548, 0.01      ])},\n",
       "                   random_state=0, scoring=make_scorer(fbeta_score, beta=10),\n",
       "                   verbose=2)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;sampling&#x27;, SMOTE()),\n",
       "                (&#x27;classification&#x27;, LogisticRegression())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" ><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SMOTE</label><div class=\"sk-toggleable__content\"><pre>SMOTE()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" ><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=5,\n",
       "                   estimator=Pipeline(steps=[('sampling', SMOTE()),\n",
       "                                             ('classification',\n",
       "                                              LogisticRegression())]),\n",
       "                   n_iter=100, n_jobs=-1,\n",
       "                   param_distributions={'classification__C': array([1.00000000e-05, 1.02331658e-05, 1.04717682e-05, 1.07159340e-05,\n",
       "       1.09657929e-05, 1.12214777e-05, 1.14831241e-05, 1.17508713e-05,\n",
       "       1.20248614e-05, 1.23052400e-05, 1.25921561e-05, 1.2...\n",
       "       0.00259502, 0.00271859, 0.00284804, 0.00298365, 0.00312572,\n",
       "       0.00327455, 0.00343047, 0.00359381, 0.00376494, 0.00394421,\n",
       "       0.00413201, 0.00432876, 0.00453488, 0.00475081, 0.00497702,\n",
       "       0.00521401, 0.00546228, 0.00572237, 0.00599484, 0.00628029,\n",
       "       0.00657933, 0.00689261, 0.00722081, 0.00756463, 0.00792483,\n",
       "       0.00830218, 0.00869749, 0.00911163, 0.00954548, 0.01      ])},\n",
       "                   random_state=0, scoring=make_scorer(fbeta_score, beta=10),\n",
       "                   verbose=2)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_logi_ftwo.fit(X_train_sample,y_train_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ffa343f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'classification__tol': 0.0022570197196339213,\n",
       " 'classification__solver': 'liblinear',\n",
       " 'classification__penalty': 'l1',\n",
       " 'classification__max_iter': 1300,\n",
       " 'classification__C': 2389.8925662310526}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_logi_ftwo.best_params_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d1f205c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_param = {'classification__tol': [0.0022570197196339213],\n",
    "                'classification__solver': ['liblinear'],\n",
    "                'classification__penalty': ['l1'],\n",
    "                'classification__max_iter': [1500],\n",
    "                'classification__C': [49.73895958790068]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "07fcfb96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>score</th>\n",
       "      <th>best_params</th>\n",
       "      <th>best_score</th>\n",
       "      <th>train</th>\n",
       "      <th>test</th>\n",
       "      <th>fbeta_score_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>search_gradiant</td>\n",
       "      <td>ftwo</td>\n",
       "      <td>{'classification__tol': 0.0009326033468832199,...</td>\n",
       "      <td>0.613480</td>\n",
       "      <td>0.644248</td>\n",
       "      <td>0.624637</td>\n",
       "      <td>0.624637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>search_gradiant</td>\n",
       "      <td>ftwo</td>\n",
       "      <td>{'classification__tol': 0.0022570197196339213,...</td>\n",
       "      <td>0.626346</td>\n",
       "      <td>0.654305</td>\n",
       "      <td>0.662170</td>\n",
       "      <td>0.662170</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             model score                                        best_params  \\\n",
       "0  search_gradiant  ftwo  {'classification__tol': 0.0009326033468832199,...   \n",
       "0  search_gradiant  ftwo  {'classification__tol': 0.0022570197196339213,...   \n",
       "\n",
       "   best_score     train      test  fbeta_score_test  \n",
       "0    0.613480  0.644248  0.624637          0.624637  \n",
       "0    0.626346  0.654305  0.662170          0.662170  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_model = search_logi_ftwo\n",
    "\n",
    "y_predict = current_model.predict(X_test)\n",
    "\n",
    "report_new = pd.DataFrame({'model':'search_gradiant','score':['ftwo'],'best_params':[current_model.best_params_],\\\n",
    "          'best_score':[current_model.best_score_],'train':[current_model.score(X_train, y_train)],\\\n",
    "          'test':[current_model.score(X_test, y_test)],'fbeta_score_test':[fbeta_score(y_test,y_predict,beta=10)]})\n",
    "\n",
    "report_final = pd.concat([report_final,report_new])\n",
    "report_final\n",
    "\n",
    "# Par erreur, on a appellé le modèle search_gradiant au lieu de search_logi\n",
    "# Par erreur le score fbeta a été appellé ftwo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0f29f2d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Essayons avec roc_auc\n",
    "\n",
    "search_logi_roc = RandomizedSearchCV(estimator = model_logistic,scoring = roc_auc,\\\n",
    "                               param_distributions =random_grid, n_iter = 100, cv = 5,\\\n",
    "                               verbose=2, random_state=0, n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d15d38eb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Louis\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\utils\\validation.py:1141: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=5,\n",
       "                   estimator=Pipeline(steps=[(&#x27;sampling&#x27;, SMOTE()),\n",
       "                                             (&#x27;classification&#x27;,\n",
       "                                              LogisticRegression())]),\n",
       "                   n_iter=100, n_jobs=-1,\n",
       "                   param_distributions={&#x27;classification__C&#x27;: array([1.00000000e-05, 1.02331658e-05, 1.04717682e-05, 1.07159340e-05,\n",
       "       1.09657929e-05, 1.12214777e-05, 1.14831241e-05, 1.17508713e-05,\n",
       "       1.20248614e-05, 1.23052400e-05, 1.25921561e-05, 1.2...\n",
       "       0.00259502, 0.00271859, 0.00284804, 0.00298365, 0.00312572,\n",
       "       0.00327455, 0.00343047, 0.00359381, 0.00376494, 0.00394421,\n",
       "       0.00413201, 0.00432876, 0.00453488, 0.00475081, 0.00497702,\n",
       "       0.00521401, 0.00546228, 0.00572237, 0.00599484, 0.00628029,\n",
       "       0.00657933, 0.00689261, 0.00722081, 0.00756463, 0.00792483,\n",
       "       0.00830218, 0.00869749, 0.00911163, 0.00954548, 0.01      ])},\n",
       "                   random_state=0, scoring=make_scorer(roc_auc_score),\n",
       "                   verbose=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" ><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=5,\n",
       "                   estimator=Pipeline(steps=[(&#x27;sampling&#x27;, SMOTE()),\n",
       "                                             (&#x27;classification&#x27;,\n",
       "                                              LogisticRegression())]),\n",
       "                   n_iter=100, n_jobs=-1,\n",
       "                   param_distributions={&#x27;classification__C&#x27;: array([1.00000000e-05, 1.02331658e-05, 1.04717682e-05, 1.07159340e-05,\n",
       "       1.09657929e-05, 1.12214777e-05, 1.14831241e-05, 1.17508713e-05,\n",
       "       1.20248614e-05, 1.23052400e-05, 1.25921561e-05, 1.2...\n",
       "       0.00259502, 0.00271859, 0.00284804, 0.00298365, 0.00312572,\n",
       "       0.00327455, 0.00343047, 0.00359381, 0.00376494, 0.00394421,\n",
       "       0.00413201, 0.00432876, 0.00453488, 0.00475081, 0.00497702,\n",
       "       0.00521401, 0.00546228, 0.00572237, 0.00599484, 0.00628029,\n",
       "       0.00657933, 0.00689261, 0.00722081, 0.00756463, 0.00792483,\n",
       "       0.00830218, 0.00869749, 0.00911163, 0.00954548, 0.01      ])},\n",
       "                   random_state=0, scoring=make_scorer(roc_auc_score),\n",
       "                   verbose=2)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-14\" type=\"checkbox\" ><label for=\"sk-estimator-id-14\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;sampling&#x27;, SMOTE()),\n",
       "                (&#x27;classification&#x27;, LogisticRegression())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-15\" type=\"checkbox\" ><label for=\"sk-estimator-id-15\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SMOTE</label><div class=\"sk-toggleable__content\"><pre>SMOTE()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-16\" type=\"checkbox\" ><label for=\"sk-estimator-id-16\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=5,\n",
       "                   estimator=Pipeline(steps=[('sampling', SMOTE()),\n",
       "                                             ('classification',\n",
       "                                              LogisticRegression())]),\n",
       "                   n_iter=100, n_jobs=-1,\n",
       "                   param_distributions={'classification__C': array([1.00000000e-05, 1.02331658e-05, 1.04717682e-05, 1.07159340e-05,\n",
       "       1.09657929e-05, 1.12214777e-05, 1.14831241e-05, 1.17508713e-05,\n",
       "       1.20248614e-05, 1.23052400e-05, 1.25921561e-05, 1.2...\n",
       "       0.00259502, 0.00271859, 0.00284804, 0.00298365, 0.00312572,\n",
       "       0.00327455, 0.00343047, 0.00359381, 0.00376494, 0.00394421,\n",
       "       0.00413201, 0.00432876, 0.00453488, 0.00475081, 0.00497702,\n",
       "       0.00521401, 0.00546228, 0.00572237, 0.00599484, 0.00628029,\n",
       "       0.00657933, 0.00689261, 0.00722081, 0.00756463, 0.00792483,\n",
       "       0.00830218, 0.00869749, 0.00911163, 0.00954548, 0.01      ])},\n",
       "                   random_state=0, scoring=make_scorer(roc_auc_score),\n",
       "                   verbose=2)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_logi_roc.fit(X_train_sample,y_train_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f9535dcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'classification__tol': 0.0016297508346206436,\n",
       " 'classification__solver': 'liblinear',\n",
       " 'classification__penalty': 'l1',\n",
       " 'classification__max_iter': 1300,\n",
       " 'classification__C': 465.2299523960189}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_logi_roc.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f4c35093",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_param_roc = {'classification__tol': [0.0016297508346206436],\n",
    "                'classification__solver': ['liblinear'],\n",
    "                'classification__penalty': ['l1'],\n",
    "                'classification__max_iter': [1300],\n",
    "                'classification__C': [465.2299523960189]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d71edd50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>score</th>\n",
       "      <th>best_params</th>\n",
       "      <th>best_score</th>\n",
       "      <th>train</th>\n",
       "      <th>test</th>\n",
       "      <th>fbeta_score_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>search_gradiant</td>\n",
       "      <td>ftwo</td>\n",
       "      <td>{'classification__tol': 0.0009326033468832199,...</td>\n",
       "      <td>0.613480</td>\n",
       "      <td>0.644248</td>\n",
       "      <td>0.624637</td>\n",
       "      <td>0.624637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>search_gradiant</td>\n",
       "      <td>ftwo</td>\n",
       "      <td>{'classification__tol': 0.0022570197196339213,...</td>\n",
       "      <td>0.626346</td>\n",
       "      <td>0.654305</td>\n",
       "      <td>0.662170</td>\n",
       "      <td>0.662170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>search_gradiant</td>\n",
       "      <td>ftwo</td>\n",
       "      <td>{'classification__tol': 0.0016297508346206436,...</td>\n",
       "      <td>0.655095</td>\n",
       "      <td>0.664117</td>\n",
       "      <td>0.667156</td>\n",
       "      <td>0.630892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>search_gradiant</td>\n",
       "      <td>roc</td>\n",
       "      <td>{'classification__tol': 0.0016297508346206436,...</td>\n",
       "      <td>0.655095</td>\n",
       "      <td>0.664117</td>\n",
       "      <td>0.667156</td>\n",
       "      <td>0.630892</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             model score                                        best_params  \\\n",
       "0  search_gradiant  ftwo  {'classification__tol': 0.0009326033468832199,...   \n",
       "0  search_gradiant  ftwo  {'classification__tol': 0.0022570197196339213,...   \n",
       "0  search_gradiant  ftwo  {'classification__tol': 0.0016297508346206436,...   \n",
       "0  search_gradiant   roc  {'classification__tol': 0.0016297508346206436,...   \n",
       "\n",
       "   best_score     train      test  fbeta_score_test  \n",
       "0    0.613480  0.644248  0.624637          0.624637  \n",
       "0    0.626346  0.654305  0.662170          0.662170  \n",
       "0    0.655095  0.664117  0.667156          0.630892  \n",
       "0    0.655095  0.664117  0.667156          0.630892  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_model = search_logi_roc\n",
    "\n",
    "y_predict = current_model.predict(X_test)\n",
    "\n",
    "report_new = pd.DataFrame({'model':'search_gradiant','score':['roc'],'best_params':[current_model.best_params_],\\\n",
    "          'best_score':[current_model.best_score_],'train':[current_model.score(X_train, y_train)],\\\n",
    "          'test':[current_model.score(X_test, y_test)],'fbeta_score_test':[fbeta_score(y_test,y_predict,beta=10)]})\n",
    "\n",
    "report_final = pd.concat([report_final,report_new])\n",
    "report_final\n",
    "\n",
    "# Par erreur, on a appellé le modèle search_gradiant au lieu de search_logi\n",
    "# Par erreur, on a appellé le roc ftwo. C'est celui qui est à la troisième ligne. Il a été refait avec l'appellation correcte\n",
    "# à la quatrième ligne\n",
    "# Par erreur le score fbeta a été appellé ftwo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b8431ec",
   "metadata": {},
   "source": [
    "# Fine tune sur le X_train complet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "fef80249",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_logi_fwto_final = RandomizedSearchCV(estimator = model_logistic,scoring = ftwo_scorer,\\\n",
    "                               param_distributions =best_param, n_iter = 20, cv = 5,\\\n",
    "                               verbose=2, random_state=0, n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "37bef9ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_logi_roc_final = RandomizedSearchCV(estimator = model_logistic,scoring = roc_auc,\\\n",
    "                               param_distributions =best_param_roc, n_iter = 20, cv = 5,\\\n",
    "                               verbose=2, random_state=0, n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6bf09282",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Louis\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\model_selection\\_search.py:306: UserWarning: The total space of parameters 1 is smaller than n_iter=20. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Louis\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\utils\\validation.py:1141: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-7 {color: black;background-color: white;}#sk-container-id-7 pre{padding: 0;}#sk-container-id-7 div.sk-toggleable {background-color: white;}#sk-container-id-7 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-7 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-7 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-7 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-7 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-7 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-7 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-7 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-7 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-7 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-7 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-7 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-7 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-7 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-7 div.sk-item {position: relative;z-index: 1;}#sk-container-id-7 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-7 div.sk-item::before, #sk-container-id-7 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-7 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-7 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-7 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-7 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-7 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-7 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-7 div.sk-label-container {text-align: center;}#sk-container-id-7 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-7 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-7\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=5,\n",
       "                   estimator=Pipeline(steps=[(&#x27;sampling&#x27;, SMOTE()),\n",
       "                                             (&#x27;classification&#x27;,\n",
       "                                              LogisticRegression())]),\n",
       "                   n_iter=20, n_jobs=-1,\n",
       "                   param_distributions={&#x27;classification__C&#x27;: [49.73895958790068],\n",
       "                                        &#x27;classification__max_iter&#x27;: [1500],\n",
       "                                        &#x27;classification__penalty&#x27;: [&#x27;l1&#x27;],\n",
       "                                        &#x27;classification__solver&#x27;: [&#x27;liblinear&#x27;],\n",
       "                                        &#x27;classification__tol&#x27;: [0.0022570197196339213]},\n",
       "                   random_state=0, scoring=make_scorer(fbeta_score, beta=10),\n",
       "                   verbose=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-25\" type=\"checkbox\" ><label for=\"sk-estimator-id-25\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=5,\n",
       "                   estimator=Pipeline(steps=[(&#x27;sampling&#x27;, SMOTE()),\n",
       "                                             (&#x27;classification&#x27;,\n",
       "                                              LogisticRegression())]),\n",
       "                   n_iter=20, n_jobs=-1,\n",
       "                   param_distributions={&#x27;classification__C&#x27;: [49.73895958790068],\n",
       "                                        &#x27;classification__max_iter&#x27;: [1500],\n",
       "                                        &#x27;classification__penalty&#x27;: [&#x27;l1&#x27;],\n",
       "                                        &#x27;classification__solver&#x27;: [&#x27;liblinear&#x27;],\n",
       "                                        &#x27;classification__tol&#x27;: [0.0022570197196339213]},\n",
       "                   random_state=0, scoring=make_scorer(fbeta_score, beta=10),\n",
       "                   verbose=2)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-26\" type=\"checkbox\" ><label for=\"sk-estimator-id-26\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;sampling&#x27;, SMOTE()),\n",
       "                (&#x27;classification&#x27;, LogisticRegression())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-27\" type=\"checkbox\" ><label for=\"sk-estimator-id-27\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SMOTE</label><div class=\"sk-toggleable__content\"><pre>SMOTE()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-28\" type=\"checkbox\" ><label for=\"sk-estimator-id-28\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=5,\n",
       "                   estimator=Pipeline(steps=[('sampling', SMOTE()),\n",
       "                                             ('classification',\n",
       "                                              LogisticRegression())]),\n",
       "                   n_iter=20, n_jobs=-1,\n",
       "                   param_distributions={'classification__C': [49.73895958790068],\n",
       "                                        'classification__max_iter': [1500],\n",
       "                                        'classification__penalty': ['l1'],\n",
       "                                        'classification__solver': ['liblinear'],\n",
       "                                        'classification__tol': [0.0022570197196339213]},\n",
       "                   random_state=0, scoring=make_scorer(fbeta_score, beta=10),\n",
       "                   verbose=2)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_logi_fwto_final.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "79eca7c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Louis\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\model_selection\\_search.py:306: UserWarning: The total space of parameters 1 is smaller than n_iter=20. Running 1 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Louis\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\utils\\validation.py:1141: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-6 {color: black;background-color: white;}#sk-container-id-6 pre{padding: 0;}#sk-container-id-6 div.sk-toggleable {background-color: white;}#sk-container-id-6 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-6 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-6 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-6 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-6 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-6 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-6 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-6 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-6 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-6 div.sk-item {position: relative;z-index: 1;}#sk-container-id-6 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-6 div.sk-item::before, #sk-container-id-6 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-6 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-6 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-6 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-6 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-6 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-6 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-6 div.sk-label-container {text-align: center;}#sk-container-id-6 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-6 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=5,\n",
       "                   estimator=Pipeline(steps=[(&#x27;sampling&#x27;, SMOTE()),\n",
       "                                             (&#x27;classification&#x27;,\n",
       "                                              LogisticRegression())]),\n",
       "                   n_iter=20, n_jobs=-1,\n",
       "                   param_distributions={&#x27;classification__C&#x27;: [465.2299523960189],\n",
       "                                        &#x27;classification__max_iter&#x27;: [1300],\n",
       "                                        &#x27;classification__penalty&#x27;: [&#x27;l1&#x27;],\n",
       "                                        &#x27;classification__solver&#x27;: [&#x27;liblinear&#x27;],\n",
       "                                        &#x27;classification__tol&#x27;: [0.0016297508346206436]},\n",
       "                   random_state=0, scoring=make_scorer(roc_auc_score),\n",
       "                   verbose=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-21\" type=\"checkbox\" ><label for=\"sk-estimator-id-21\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=5,\n",
       "                   estimator=Pipeline(steps=[(&#x27;sampling&#x27;, SMOTE()),\n",
       "                                             (&#x27;classification&#x27;,\n",
       "                                              LogisticRegression())]),\n",
       "                   n_iter=20, n_jobs=-1,\n",
       "                   param_distributions={&#x27;classification__C&#x27;: [465.2299523960189],\n",
       "                                        &#x27;classification__max_iter&#x27;: [1300],\n",
       "                                        &#x27;classification__penalty&#x27;: [&#x27;l1&#x27;],\n",
       "                                        &#x27;classification__solver&#x27;: [&#x27;liblinear&#x27;],\n",
       "                                        &#x27;classification__tol&#x27;: [0.0016297508346206436]},\n",
       "                   random_state=0, scoring=make_scorer(roc_auc_score),\n",
       "                   verbose=2)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-22\" type=\"checkbox\" ><label for=\"sk-estimator-id-22\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;sampling&#x27;, SMOTE()),\n",
       "                (&#x27;classification&#x27;, LogisticRegression())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-23\" type=\"checkbox\" ><label for=\"sk-estimator-id-23\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SMOTE</label><div class=\"sk-toggleable__content\"><pre>SMOTE()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-24\" type=\"checkbox\" ><label for=\"sk-estimator-id-24\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=5,\n",
       "                   estimator=Pipeline(steps=[('sampling', SMOTE()),\n",
       "                                             ('classification',\n",
       "                                              LogisticRegression())]),\n",
       "                   n_iter=20, n_jobs=-1,\n",
       "                   param_distributions={'classification__C': [465.2299523960189],\n",
       "                                        'classification__max_iter': [1300],\n",
       "                                        'classification__penalty': ['l1'],\n",
       "                                        'classification__solver': ['liblinear'],\n",
       "                                        'classification__tol': [0.0016297508346206436]},\n",
       "                   random_state=0, scoring=make_scorer(roc_auc_score),\n",
       "                   verbose=2)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_logi_roc_final.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "850b7500",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>score</th>\n",
       "      <th>best_params</th>\n",
       "      <th>best_score</th>\n",
       "      <th>train</th>\n",
       "      <th>test</th>\n",
       "      <th>fbeta_score_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>search_gradiant</td>\n",
       "      <td>fwto</td>\n",
       "      <td>{'classification__tol': 0.0022570197196339213,...</td>\n",
       "      <td>0.637733</td>\n",
       "      <td>0.648908</td>\n",
       "      <td>0.63121</td>\n",
       "      <td>0.63121</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             model score                                        best_params  \\\n",
       "0  search_gradiant  fwto  {'classification__tol': 0.0022570197196339213,...   \n",
       "\n",
       "   best_score     train     test  fbeta_score_test  \n",
       "0    0.637733  0.648908  0.63121           0.63121  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_model = search_logi_fwto_final\n",
    "\n",
    "y_predict = current_model.predict(X_test)\n",
    "\n",
    "report_new_1 = pd.DataFrame({'model':'search_gradiant','score':['fwto'],'best_params':[current_model.best_params_],\\\n",
    "          'best_score':[current_model.best_score_],'train':[current_model.score(X_train, y_train)],\\\n",
    "          'test':[current_model.score(X_test, y_test)],'fbeta_score_test':[fbeta_score(y_test,y_predict,beta=10)]})\n",
    "\n",
    "#report_final = pd.concat([report_final,report_new])\n",
    "#report_final\n",
    "\n",
    "report_new_1\n",
    "\n",
    "# Par erreur, on a appellé le modèle search_gradiant au lieu de search_logi\n",
    "# Par erreur le score fbeta a été appellé ftwo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8965f3b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>score</th>\n",
       "      <th>best_params</th>\n",
       "      <th>best_score</th>\n",
       "      <th>train</th>\n",
       "      <th>test</th>\n",
       "      <th>fbeta_score_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>search_gradiant</td>\n",
       "      <td>roc</td>\n",
       "      <td>{'classification__tol': 0.0016297508346206436,...</td>\n",
       "      <td>0.669061</td>\n",
       "      <td>0.670158</td>\n",
       "      <td>0.672751</td>\n",
       "      <td>0.637546</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             model score                                        best_params  \\\n",
       "0  search_gradiant   roc  {'classification__tol': 0.0016297508346206436,...   \n",
       "\n",
       "   best_score     train      test  fbeta_score_test  \n",
       "0    0.669061  0.670158  0.672751          0.637546  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_model = search_logi_roc_final\n",
    "\n",
    "y_predict = current_model.predict(X_test)\n",
    "\n",
    "report_new_1 = pd.DataFrame({'model':'search_gradiant','score':['roc'],'best_params':[current_model.best_params_],\\\n",
    "          'best_score':[current_model.best_score_],'train':[current_model.score(X_train, y_train)],\\\n",
    "          'test':[current_model.score(X_test, y_test)],'fbeta_score_test':[fbeta_score(y_test,y_predict,beta=10)]})\n",
    "\n",
    "#report_final = pd.concat([report_final,report_new])\n",
    "#report_final\n",
    "\n",
    "report_new_1\n",
    "\n",
    "# Par erreur, on a appellé le modèle search_gradiant au lieu de search_logi\n",
    "# Par erreur le score fbeta a été appellé ftwo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "63b187be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Le roc_auc semble être celui qui overfit le moins"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c77a084",
   "metadata": {},
   "source": [
    "# Fine tune Threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ae9a8c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On fait quelques tests pour voir l'effet du threshold sur notre score final."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "0e44848d",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_test = pd.DataFrame(search_logi_roc_final.predict_proba(X_test))[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "602c61af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def threshold_test(threshold,prediction):\n",
    "    return  np.array(prediction.apply(lambda x : 1 if (x >= threshold)else 0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "76276be4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "threshold :\n",
      " 0.0\n",
      "0.898460818165857 \n",
      "\n",
      "threshold :\n",
      " 0.1\n",
      "0.9017857142857143 \n",
      "\n",
      "threshold :\n",
      " 0.2\n",
      "0.8916194452728899 \n",
      "\n",
      "threshold :\n",
      " 0.30000000000000004\n",
      "0.8242889335525914 \n",
      "\n",
      "threshold :\n",
      " 0.4\n",
      "0.7402484472049689 \n",
      "\n",
      "threshold :\n",
      " 0.5\n",
      "0.6375457644236839 \n",
      "\n",
      "threshold :\n",
      " 0.6000000000000001\n",
      "0.505 \n",
      "\n",
      "threshold :\n",
      " 0.7000000000000001\n",
      "0.3146213251995587 \n",
      "\n",
      "threshold :\n",
      " 0.8\n",
      "0.17183614710116477 \n",
      "\n",
      "threshold :\n",
      " 0.9\n",
      "0.03982649842271293 \n",
      "\n",
      "threshold :\n",
      " 1.0\n",
      "0.0 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "score = []\n",
    "\n",
    "for i in np.linspace(0,1,11):\n",
    "    print('threshold :\\n', i)\n",
    "    print(fbeta_score(y_test,threshold_test(i,prediction_test),beta = 10),'\\n')\n",
    "    score.append(fbeta_score(y_test,threshold_test(i,prediction_test),beta = 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "7d2f6790",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Score')"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(np.linspace(0,1,11),score)\n",
    "\n",
    "plt.title('Score en fonction du Threshold')\n",
    "\n",
    "plt.xlabel('Threshold')\n",
    "plt.ylabel('Score')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ce14e8a",
   "metadata": {},
   "source": [
    "# Sauvegarde du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "099ebc9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "69d87270",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Pipeline\\\\search_logi_roc_tuned.joblib']"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(search_logi_roc_final, 'Pipeline\\search_logi_roc_tuned.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a3c119d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
